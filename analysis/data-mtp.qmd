---
title: "Data Example for The Causal Effects of Modified Treatment Policies Under Network Interference"
format: html
engine: julia
---

This Quarto notebook performs analysis for the *data example* section of Balkus, Delaney, and Hejazi (2025) "The Causal Effects of Modified Treatment Policies Under Network Interference". See `data-analysis.qmd` for code to produce plots from these results. 

### Load necessary packages
```{julia}
using DrWatson
quickactivate("analysis", "data-analysis")

using CSV, DataFrames
using CausalTables, Condensity, ModifiedTreatment
using MLJ
using Plots

using SimpleWeightedGraphs

using GLM
using Tables, TableTransforms
using LinearAlgebra
using Statistics
```

### Load data
```{julia}

# Load the dataframe
df_raw = CSV.read(joinpath("data","NO2_ZEV_ZCTAs.csv"), DataFrame)
df = DataFrames.select(sort(df_raw, :ZCTA), Not([:ZCTA, :n2_2019, :p__2013]))
df[!, "pop"] = float.(df_raw[!, "pop"]);

```

```{julia}
net_raw_2019 = CSV.read(joinpath("data","ZEV_commuters_2019.csv"), DataFrame)
net_raw_2013 = CSV.read(joinpath("data","ZEV_commuters_2013.csv"), DataFrame)

w = []
for net_raw in [net_raw_2019, net_raw_2013]
        net = filter(row -> row.h_zcta ∈ df_raw.ZCTA && row.w_zcta ∈ df_raw.ZCTA, net_raw)

        # create index mapping for adjacency matrix and replace IDs with rank
        zctas = sort(union(unique(net.w_zcta), unique(net.h_zcta)))
        zctas_dict = Dict(zctas .=> 1:length(zctas))
        net.w_zcta = map(x -> zctas_dict[x], net.w_zcta)
        net.h_zcta = map(x -> zctas_dict[x], net.h_zcta)

        # Construct graph and extract weight matrix
        g = SimpleWeightedDiGraph(net.w_zcta, net.h_zcta, net.weight)
        cur_w = g.weights
        push!(w, cur_w)
end

neighbors = .!(iszero.(w[1]))


```

### Clean data
```{julia}

# Construct CausalTable with no summarization
ct_nosum = CausalTable(df; treatment = :ZEV_2019_pct, response = :no2)

# Construct CausalTable with network summaries
ct = CausalTable(df; treatment = :ZEV_2019_pct, response = :no2, 
                arrays = (F = neighbors, w_2019 = w[1], w_2013 = w[2],), 
                summaries = (ZEV_2019_sum = Sum(:ZEV_2019_pct, :w_2019),
                                ZEV_2013_sum = Sum(:ZEV_2013_pct, :w_2013),
                                nfriends = CausalTables.Friends(:F),
                                pop_s = CausalTables.Sum(:pop, :F),
                                medin_g_s = CausalTables.Sum(:medin_g, :F),
                                pct_cll_s = CausalTables.Sum(:pct_cll, :F),
                                pct_hgh_s = CausalTables.Sum(:pct_hgh, :F),
                                pct_wht_s = CausalTables.Sum(:pct_wht, :F),
                                mdn_ncm_s = CausalTables.Sum(:mdn_ncm, :F),
                                pct_pvr_s = CausalTables.Sum(:pct_pvr, :F),
                                pct_wn__s = CausalTables.Sum(:pct_wn_, :F),
                                mdn_hm__s = CausalTables.Sum(:mdn_hm_, :F),
                                pct_aut_s = CausalTables.Sum(:pct_aut, :F),
                                pct_pb_s = CausalTables.Sum(:pct_pb_, :F),
                                pct_wfh_s = CausalTables.Sum(:pct_wfh, :F),
                                D1C5_IN_s = CausalTables.Sum(:D1C5_IN, :F),
                                D3A_s = CausalTables.Sum(:D3A, :F),
                                D4C_s = CausalTables.Sum(:D4C, :F),
                                NtWlkIn_s = CausalTables.Sum(:NtWlkIn, :F)
                ))

```

## Linear regression

```{julia}
Xtbl = CausalTables.responseparents(ct_nosum)
X = hcat(Tables.matrix(Xtbl), ones(nrow(Xtbl))) # add intercept column for design matrix
y = Tables.getcolumn(ct_nosum, ct_nosum.response[1])

# function to compute HC-consistent errors
hce(glm_fit, X) = inv((transpose(X) * X)) * (transpose(X) * LinearAlgebra.diagm(residuals(glm_fit).^2) * X) * inv((transpose(X) * X))

colnum = findfirst(Tables.columnnames(Xtbl) .== :ZEV_2019_pct)
glm_a = lm(X, y)
est_a = coef(glm_a)[colnum]
moe_a = 1.96 .* sqrt(hce(glm_a, X)[colnum,colnum] + var(y)/length(y))


glm_effect_a = (est = est_a, lower = est_a - moe_a, upper = est_a + moe_a)
#glm_effect_a = (est = est_a, lower = confint(glm_a)[1, 1], upper = confint(glm_a)[1, 2])

X[:,colnum] = log.(X[:,colnum])

glm_m = lm(X, y)
est_m = coef(glm_m)[colnum] * log(1.2)
moe_m = 1.96 .* sqrt(hce(glm_m, X)[colnum,colnum] + var(y)/length(y))

glm_effect_m = (est = est_m, lower = est_m - moe_m, upper = est_m + moe_m)
#glm_effect_m = (est = est_m, lower = confint(glm_m)[1, 1] * log(1.2), upper = confint(glm_m)[1, 2] * log(1.2))

```

## Baseline comparision function
We define this function to aid result aggregation. 
```{julia}
# Compute effect
ψ0 = mean(df.no2)
n = nrow(df)
function get_effects_tuple(mtp_result, ψ0, n; iid = true)
        mtp_ψ = mtp_result.tmle.ψ .- ψ0
        if iid
                ciwidth = 1.96 * sqrt(mtp_result.tmle.σ2)
        else
                ciwidth = 1.96 * sqrt(mtp_result.tmle.σ2net)
        end
        (est = mtp_ψ, lower = mtp_ψ - ciwidth, upper = mtp_ψ + ciwidth)
end

```

## MTP

First, define the super learners.

```{julia}
LinearRegressor = @load LinearRegressor pkg=MLJLinearModels
LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels
XGBoostRegressor = @load XGBoostRegressor pkg=XGBoost
XGBoostClassifier = @load XGBoostClassifier pkg=XGBoost
FillImputer = @load FillImputer pkg=MLJModels
DeterministicConstantRegressor = @load DeterministicConstantRegressor pkg=MLJModels
LGBMRegressor = @load LGBMRegressor pkg=LightGBM

mean_estimator = SuperLearner([
    XGBoostRegressor(objective = "reg:squarederror", booster="gblinear"),
    XGBoostRegressor(objective = "reg:squarederror", num_round = 1, 
                    colsample_bynode = 0.8, eta = 1, max_depth = 6, num_parallel_tree = 100, subsample = 0.8, tree_method = "hist"),
    XGBoostRegressor(objective = "reg:squarederror", 
                    eta = 0.1, max_depth = 6),
    XGBoostRegressor(objective = "reg:squarederror", 
                    eta = 0.01, max_depth = 6),
    XGBoostRegressor(objective = "reg:squarederror", 
                    num_round = 500, eta = 0.01, max_depth = 3),
], CV(nfolds = 5))

# We need to stick with this one because the semiparametric fares poorly due to skewed data
sl = SuperLearner([
    XGBoostClassifier(objective = "binary:logistic", booster="gblinear"),
    XGBoostClassifier(objective = "binary:logistic", num_round = 1, 
                      colsample_bynode = 0.8, eta = 1, max_depth = 6, num_parallel_tree = 100, subsample = 0.8, tree_method = "hist"),
    XGBoostClassifier(objective = "binary:logistic",
                      num_round = 100, eta = 0.1, max_depth = 6, subsample = 1.0),
    XGBoostClassifier(objective = "binary:logistic",
                      num_round = 100, eta = 0.1, max_depth = 3, subsample = 0.5),
    XGBoostClassifier(objective = "binary:logistic",
                      num_round = 500, eta = 0.01, max_depth = 3, subsample = 0.5),
], CV(nfolds = 5))

density_ratio_estimator = DensityRatioClassifier(sl)
density_ratio_estimator_iid = DensityRatioClassifier(sl)


cv_splitter = CV(nfolds = 5)
mtp = MTP(mean_estimator, density_ratio_estimator_iid, cv_splitter)
```

Then, we run the MTP with no summarized features (assuming SUTVA).

```{julia}
shift = AdditiveShift(1.0)
mach = machine(mtp, ct_nosum, shift) |> fit!
```

```{julia}
mtp_result_a = getestimate(ModifiedTreatment.estimate(mach, shift))
mtp_effect_a = get_effects_tuple(mtp_result_a, ψ0, n; iid = true)

```

Next, we run the MTP on the summarized data.

```{julia}
mtps = MTP(mean_estimator, density_ratio_estimator, cv_splitter)
mach_net_sum = machine(mtps, ct, shift) |> fit!
```

```{julia}
mtp_result_net_a_sum = getestimate(ModifiedTreatment.estimate(mach_net_sum, AdditiveShift(1.0)))
mtp_effect_net_a_sum = get_effects_tuple(mtp_result_net_a_sum, ψ0, n; iid = false)
```

```{julia}
ests = [mtp_effect_net_a_sum, mtp_effect_a, glm_effect_a]

tbl = (method = ["Induced MTP (Sum)", "MTP (No Interference)", "GLM (No Interference)"], effects = map(x -> x.est, ests), upper = map(x -> x.upper, ests), lower = map(x -> x.lower, ests))
CSV.write(joinpath("results", "mtp_analysis_a.csv"), tbl)

tbl

```

We also compute an MTP grid and save the results to a .CSV file.

```{julia}
est_grid_a = []
as = 0.2:0.2:2.0
for a in as
        shift = AdditiveShift(a)
        mtp_result_a = getestimate(estimate(mach, shift))
        mtp_result_net_a_sum = getestimate(estimate(mach_net_sum, shift))

        push!(est_grid_a, merge((shift = a, name = "MTP (No Interference)"), get_effects_tuple(mtp_result_a, ψ0, n; iid = true)))
        push!(est_grid_a, merge((shift = a, name = "Induced MTP (Sum)"), get_effects_tuple(mtp_result_net_a_sum, ψ0, n; iid = false)))

end

CSV.write(joinpath("results", "mtp_grid_a.csv"), est_grid_a)

```

Next, perform the same analysis, but with a multiplicative shift. We can reuse our previously-fitted models and evaluate them on another shift.

```{julia}

mshift = MultiplicativeShift(1.2)

mtp_result_m = getestimate(ModifiedTreatment.estimate(mach, mshift))
mtp_effect_m = get_effects_tuple(mtp_result_m, ψ0, n; iid = true)

mtp_result_net_m_sum = getestimate(ModifiedTreatment.estimate(mach_net_sum, mshift))
mtp_effect_net_m_sum = get_effects_tuple(mtp_result_net_m_sum, ψ0, n; iid = false)

ests = [mtp_effect_net_m_sum, mtp_effect_m, glm_effect_m]

tbl = (method = ["Induced MTP (Sum)", "MTP (No Interference)", "GLM (No Interference)"], effects = map(x -> x.est, ests), upper = map(x -> x.upper, ests), lower = map(x -> x.lower, ests))
CSV.write(joinpath("results", "mtp_analysis_m.csv"), tbl)


```

Finally, we compute the same estimates, except across a grid of possible shifts for the multiplicative shifts as well.
```{julia}

est_grid_m = []
as = 0.04:0.04:0.4
for a in as
        shift = MultiplicativeShift(1.0 + a)
        mtp_result_m = getestimate(estimate(mach, shift))
        mtp_result_net_m_sum = getestimate(estimate(mach_net_sum, shift))

        push!(est_grid_m, merge((shift = a, name = "MTP (No Interference)"), get_effects_tuple(mtp_result_m, ψ0, n; iid = true)))
        push!(est_grid_m, merge((shift = a, name = "Induced MTP (Sum)"), get_effects_tuple(mtp_result_net_m_sum, ψ0, n; iid = false)))
end

CSV.write(joinpath("results", "mtp_grid_m.csv"), est_grid_m)

```
